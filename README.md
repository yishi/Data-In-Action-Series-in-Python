# Data-In-Action-Series-in-Python

**[Data In Action Series 1:  Recognition of  Handwritten Digits](http://nbviewer.jupyter.org/github/yishi/Data-In-Action-Series-in-Python/blob/master/data_in_action_series_1.ipynb)**

Because of the shape of handwritten digits are complex, we find out the **k nearest neighbors** model have the best effect, and support vector machine, which kernel is polynomial, also have a good effect.


**[Data In Action Series 2:  Recognition of  Human Faces](http://nbviewer.jupyter.org/github/yishi/Data-In-Action-Series-in-Python/blob/master/data_in_action_series_2.ipynb)**

The models of **logistic regression** and support vector machine, which kernel is linear, are suitable for the recognition of human faces.


**[Data In Action Series 3:  Image Compression](http://nbviewer.jupyter.org/github/yishi/Data-In-Action-Series-in-Python/blob/master/data_in_action_series_3.ipynb)**

**K-means** model are good at image compression.


**[Data In Action Series 4:  Text Classification](http://nbviewer.jupyter.org/github/yishi/Data-In-Action-Series-in-Python/blob/master/data_in_action_series_4.ipynb)**

There are 3 methods (such as count, tf, tf-idf) to extract features from text.
Different features extraction method have different effect to text classification.
For our example data set:
**the combination of count method and multinomial naive bayes** model are best;
the combination of tf-idf method and support vector machine which kernel is linear are better than other models.




